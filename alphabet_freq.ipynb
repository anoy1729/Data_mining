{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "alphabet_freq.ipynb",
      "provenance": [],
      "mount_file_id": "1B1uBpBP7N3aN_5vq4CVT5BplTEUi_26E",
      "authorship_tag": "ABX9TyNBDQZdLGPRHJhDn1F2bllD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anoy1729/Data_mining/blob/main/alphabet_freq.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gP30SW-CHMKA"
      },
      "source": [
        "import csv\n",
        "import sys\n",
        "from itertools import groupby\n",
        "from operator import itemgetter\n",
        "import numpy as np\n",
        "import regex\n",
        "from collections import Counter\n",
        "import os\n",
        "\n",
        "\n",
        "\n",
        "URL_LINK = '/content/drive/MyDrive/Assignment_2/Bigram/frequencywisesort.csv'\n",
        "CSV_LINK = '/content/drive/MyDrive/Assignment_2/Alphabet/characterwise_bigram.csv'\n",
        "\n",
        "def append_to_csv(row):\n",
        "    global CSV_LINK\n",
        "    with open(CSV_LINK, mode='a', newline='', encoding='utf-8') as unit_new_article:\n",
        "        news_article_writer = csv.writer(unit_new_article, delimiter=' ', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
        "        news_article_writer.writerow(row)\n",
        "    pass\n",
        "\n",
        "with open(URL_LINK, encoding='utf-8') as unit_url_csv:\n",
        "    readCSV = csv.reader(unit_url_csv)\n",
        "    UniDict = {}\n",
        "    UniqueWordlist = []\n",
        "    for row in readCSV:\n",
        "        Wordlist = regex.findall(r\"[\\w{Bengali}]+[\\s]+[\\w{Bengali}]+\", row[1])\n",
        "        UniqueWordlist.extend(Wordlist)\n",
        "\n",
        "    for letter, words in groupby(sorted(UniqueWordlist), key=itemgetter(0)):\n",
        "        char = Counter(words)\n",
        "        f = len(char)\n",
        "        input_array = [letter, f]\n",
        "        append_to_csv(input_array)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}